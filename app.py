# app.py
import os, io, logging
from pathlib import Path
from typing import Dict, Any, List

from flask import Flask, request, jsonify, abort
from PIL import Image
import numpy as np

# ===== Optional CV (è‹¥éœ€åšåœ–ç‰‡è§£æå¯ç”¨åˆ°) =====
try:
    import cv2
except Exception:
    cv2 = None

# ===== LINE SDKï¼ˆå…è¨±æ²’è¨­ Token ä¹Ÿèƒ½å•Ÿå‹•ï¼‰ =====
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, ImageMessage, TextSendMessage, FollowEvent
)

# ===== Optional ML =====
try:
    import joblib
except Exception:
    joblib = None

try:
    import xgboost as xgb
except Exception:
    xgb = None

try:
    import lightgbm as lgb
except Exception:
    lgb = None

try:
    from hmmlearn.hmm import MultinomialHMM
except Exception:
    MultinomialHMM = None


# -----------------------------------------
# Flask & Logging
# -----------------------------------------
app = Flask(__name__)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("bgs-bot")


# -----------------------------------------
# ENVï¼ˆå…è¨±æœ¬åœ°èˆ‡é›²ç«¯ï¼‰
# -----------------------------------------
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")

# æ²’æœ‰ Token ä¹Ÿèƒ½å•Ÿå‹•ï¼ˆæ–¹ä¾¿æœ¬åœ°æ¸¬è©¦/API æ¨¡æ“¬ï¼‰
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN) if LINE_CHANNEL_ACCESS_TOKEN else None
line_handler = WebhookHandler(LINE_CHANNEL_SECRET if LINE_CHANNEL_SECRET else "DUMMY_SECRET")


# -----------------------------------------
# æ¨¡å‹è¼‰å…¥ï¼ˆå­˜åœ¨å°±ç”¨ï¼Œä¸å­˜åœ¨èµ°è¦å‰‡æ©Ÿï¼‰
# -----------------------------------------
MODELS_DIR = Path("models")
SCALER_PATH = MODELS_DIR / "scaler.pkl"
XGB_PKL     = MODELS_DIR / "xgb_model.pkl"
XGB_JSON    = MODELS_DIR / "xgb_model.json"
XGB_UBJ     = MODELS_DIR / "xgb_model.ubj"
LGBM_PKL    = MODELS_DIR / "lgbm_model.pkl"
LGBM_TXT    = MODELS_DIR / "lgbm_model.txt"
LGBM_JSON   = MODELS_DIR / "lgbm_model.json"
HMM_PKL     = MODELS_DIR / "hmm_model.pkl"

model_bundle: Dict[str, Any] = {}

def _safe_exists(p: Path) -> bool:
    try:
        return p.exists()
    except Exception:
        return False

def load_models():
    global model_bundle
    bundle: Dict[str, Any] = {}
    try:
        if joblib and _safe_exists(SCALER_PATH):
            bundle["scaler"] = joblib.load(SCALER_PATH)

        # XGB
        if xgb:
            if _safe_exists(XGB_PKL) and joblib:
                bundle["xgb_sklearn"] = joblib.load(XGB_PKL)
            elif _safe_exists(XGB_JSON):
                booster = xgb.Booster()
                booster.load_model(str(XGB_JSON))
                bundle["xgb_booster"] = booster
            elif _safe_exists(XGB_UBJ):
                booster = xgb.Booster()
                booster.load_model(str(XGB_UBJ))
                bundle["xgb_booster"] = booster

        # LGBM
        if lgb:
            if _safe_exists(LGBM_PKL) and joblib:
                bundle["lgbm_sklearn"] = joblib.load(LGBM_PKL)
            elif _safe_exists(LGBM_TXT):
                bundle["lgbm_booster"] = lgb.Booster(model_file=str(LGBM_TXT))
            elif _safe_exists(LGBM_JSON):
                bundle["lgbm_booster"] = lgb.Booster(model_file=str(LGBM_JSON))

        # HMM
        if MultinomialHMM and _safe_exists(HMM_PKL) and joblib:
            bundle["hmm"] = joblib.load(HMM_PKL)

        bundle["loaded"] = any(k in bundle for k in (
            "xgb_sklearn", "xgb_booster", "lgbm_sklearn", "lgbm_booster", "hmm"
        ))
        bundle["note"] = "at least one model loaded" if bundle["loaded"] else "no model file found"
        model_bundle = bundle
        logger.info(f"[models] loaded={bundle['loaded']} note={bundle['note']}")
    except Exception as e:
        model_bundle = {"loaded": False, "note": f"load error: {e}"}
        logger.exception(f"[models] load error: {e}")

load_models()


# -----------------------------------------
# å·¥å…·ï¼šè§£æ B/P/Tï¼ˆæ”¯æ´ä¸­æ–‡ã€é€—è™Ÿã€å¤§å°å¯«ï¼‰
# -----------------------------------------
def parse_seq_from_text(text: str) -> List[str]:
    if not text:
        return []
    try:
        import unicodedata
        text = unicodedata.normalize("NFKC", text)
    except Exception:
        pass
    t = text.upper().replace(",", " ").replace("ï¼Œ", " ").replace("|", " ").replace("/", " ")
    mapping = {
        "èŠ": "B", "èŠå®¶": "B", "BANKER": "B", "Z": "B",
        "é–’": "P", "é–’å®¶": "P", "PLAYER": "P", "X": "P",
        "å’Œ": "T", "å’Œå±€": "T", "TIE": "T", "H": "T"
    }
    tokens: List[str] = []
    for raw in t.split():
        if raw in ("B", "P", "T"):
            tokens.append(raw)
        else:
            r = "".join(ch for ch in raw if ch.isalnum() or ch in ("B", "P", "T"))
            if r in ("B", "P", "T"):
                tokens.append(r)
            elif raw in mapping:
                tokens.append(mapping[raw])
    return tokens

def clean(seq: List[str]) -> List[str]:
    return [s for s in seq if s in ("B","P","T")]

def _streak_tail(seq: List[str], target: str) -> int:
    t = 0
    for s in reversed(seq):
        if s == target:
            t += 1
        else:
            break
    return t

def _transitions(seq: List[str]) -> Dict[str,int]:
    c = {"BB":0,"BP":0,"PP":0,"PB":0}
    for a,b in zip(seq, seq[1:]):
        if a in "BP" and b in "BP":
            c[a+b]+=1
    return c

def _ratio_lastN(seq: List[str], target: str, N: int=20) -> float:
    last = seq[-N:] if len(seq)>N else seq
    n = sum(1 for s in last if s==target)
    d = sum(1 for s in last if s in "BP")
    return (n/d) if d else 0.5

def build_features(seq: List[str]) -> np.ndarray:
    seq = clean(seq)
    arr = np.array([
        _streak_tail(seq,"B"),
        _streak_tail(seq,"P"),
        _ratio_lastN(seq,"B",20),
        _ratio_lastN(seq,"P",20),
        _transitions(seq)["BB"],
        _transitions(seq)["PP"],
        _transitions(seq)["BP"],
        _transitions(seq)["PB"],
    ], dtype=float).reshape(1,-1)
    return arr

def _normalize(p: np.ndarray) -> np.ndarray:
    s = p.sum()
    return (p/s) if s>0 else np.array([1/3,1/3,1/3])

def _proba_from_xgb(X: np.ndarray) -> np.ndarray:
    # ä¾ä½ çš„æ¨¡å‹å¯¦ä½œï¼›æ­¤è™•å…ˆçµ¦ placeholder
    return np.array([0.34,0.33,0.33])

def _proba_from_lgb(X: np.ndarray) -> np.ndarray:
    return np.array([0.34,0.33,0.33])

def _proba_from_hmm(seq: List[str]) -> np.ndarray:
    return np.array([0.34,0.33,0.33])

def predict_with_models(seq: List[str]) -> Dict[str,float]:
    X = build_features(seq)
    ps = []
    if model_bundle.get("xgb_sklearn") or model_bundle.get("xgb_booster"):
        ps.append(_proba_from_xgb(X))
    if model_bundle.get("lgbm_sklearn") or model_bundle.get("lgbm_booster"):
        ps.append(_proba_from_lgb(X))
    if model_bundle.get("hmm"):
        ps.append(_proba_from_hmm(seq))
    if not ps:
        ps = [np.array([0.34,0.33,0.33])]
    mean = _normalize(np.mean(ps, axis=0))
    return {"banker": float(mean[0]), "player": float(mean[1]), "tie": float(mean[2])}

def predict_probs_from_seq_rule(seq: List[str]) -> Dict[str,float]:
    # å‚™æ´è¦å‰‡æ©Ÿï¼ˆç„¡æ¨¡å‹æ™‚ï¼‰
    b = 0.5 + 0.1 * (_ratio_lastN(seq,"B",12) - 0.5)
    p = 1 - b
    t = 0.02
    s = b + p + t
    return {"banker": b/s, "player": p/s, "tie": t/s}


# -----------------------------------------
# å½±åƒâ†’åºåˆ—ï¼ˆä½”ä½ï¼šå›å‚³ []ï¼›ä¹‹å¾Œæ¥ä¸Šä½ çš„ CV ç®¡ç·šï¼‰
# -----------------------------------------
def extract_sequence_from_image(img: Image.Image) -> List[str]:
    # TODO: æ¥ä¸Šä½ çš„ç‰Œè·¯ OCR/è‰²å¡Š/ç·šæ®µåµæ¸¬ï¼Œè¼¸å‡º ["B","P","B","T",...]
    return []


# -----------------------------------------
# è³‡é‡‘åˆ†é…ï¼ˆç¶­æŒä½ çš„æª”ä½ï¼š0/2/4/8/12%ï¼‰
# -----------------------------------------
def betting_plan(pb: float, pp: float) -> Dict[str, Any]:
    diff = abs(pb-pp)
    side = "èŠ" if pb >= pp else "é–’"
    side_prob = max(pb, pp)
    if diff < 0.05:
        return {"side": side, "percent": 0.0, "side_prob": side_prob, "note": "å·®è·ä¸è¶³ 5%ï¼Œé¢¨éšªé«˜"}
    if diff < 0.08: pct = 0.02
    elif diff < 0.12: pct = 0.04
    elif diff < 0.18: pct = 0.08
    else: pct = 0.12
    return {"side": side, "percent": pct, "side_prob": side_prob}


# -----------------------------------------
# é¡¯ç¤ºæ•´åˆï¼ˆè³‡é‡‘ï¼‹æ–¹å‘ï¼›<12% é¡›å€’é¡¯ç¤ºï¼‰
# -----------------------------------------
def render_reply(seq: List[str], probs: Dict[str,float], by_model: bool) -> str:
    b, p, t = probs["banker"], probs["player"], probs["tie"]
    plan = betting_plan(b, p)
    tag = "ï¼ˆæ¨¡å‹ï¼‰" if by_model else "ï¼ˆè¦å‰‡ï¼‰"
    win_txt = f"{plan['side_prob']*100:.1f}%"
    note = f"ï½œ{plan['note']}" if plan.get("note") else ""

    # percent == 0 â†’ è§€æœ›ï¼› 0<percent<0.12 â†’ é¡¯ç¤ºæ–¹å‘é¡›å€’ï¼› >=0.12 â†’ ä¸é¡›å€’
    if plan["percent"] == 0.0:
        advise_text = "è§€æœ›"
    else:
        if plan["percent"] < 0.12:
            show_side = "é–’" if plan["side"] == "èŠ" else "èŠ"
        else:
            show_side = plan["side"]
        advise_text = f"æ–¼ã€Œ{show_side}ã€ä¸‹æ³¨ {int(plan['percent']*100)}%"

    return (
        f"{tag} å·²è§£æ {len(seq)} æ‰‹\n"
        f"å»ºè­°ï¼ˆè³‡é‡‘+æ–¹å‘ï¼‰ï¼š{advise_text}ï¼ˆå‹ç‡ {win_txt}ï¼‰{note}\n"
        f"æ©Ÿç‡ï¼šèŠ {b:.2f}ï½œé–’ {p:.2f}ï½œå’Œ {t:.2f}"
    )


# -----------------------------------------
# Flask Routes
# -----------------------------------------
@app.route("/")
def index():
    return "BGS AI åŠ©æ‰‹æ­£åœ¨é‹è¡Œ âœ… /health /api/simulate /line-webhook"

@app.route("/health")
def health():
    return jsonify({"ok": True, "models": model_bundle.get("note","")})

# æ–¹ä¾¿æœ¬åœ° / é›²ç«¯ç„¡ LINE æ™‚è‡ªæ¸¬
@app.route("/api/simulate", methods=["POST"])
def simulate():
    data = request.get_json(force=True, silent=True) or {}
    text = (data.get("text") or "").strip()
    seq = parse_seq_from_text(text)
    if not seq:
        return jsonify({"error":"è«‹æä¾›åºåˆ—ï¼Œä¾‹å¦‚ï¼š'B P P B T' æˆ– 'èŠ é–’ é–’ èŠ å’Œ'"}), 400
    probs = predict_with_models(seq) if model_bundle.get("loaded") else predict_probs_from_seq_rule(seq)
    reply = render_reply(seq, probs, by_model=model_bundle.get("loaded", False))
    return jsonify({"reply": reply, "seq": seq, "probs": probs})


# ============ LINE Webhook ============
@app.route("/line-webhook", methods=["POST"])
def line_webhook():
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)
    try:
        line_handler.handle(body, signature)
    except InvalidSignatureError:
        # æ²’è¨­å®šæ­£ç¢º secret æ™‚ï¼Œé€™è£¡å¯èƒ½å ±éŒ¯
        abort(400, "Invalid signature")
    return "OK"

@line_handler.add(FollowEvent)
def on_follow(event: FollowEvent):
    if line_bot_api:
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage("æ­¡è¿åŠ å…¥ï¼\n- è²¼æ–‡å­—ï¼šB/P/T æˆ– èŠ/é–’/å’Œï¼ˆå¯ç”¨é€—è™Ÿæˆ–ç©ºç™½åˆ†éš”ï¼‰\n- è²¼åœ–ç‰‡ï¼šå¯è§£æå¤§è·¯/ä¸‹ä¸‰è·¯ï¼ˆæ¸…æ™°ã€å®Œæ•´ï¼‰")
        )

@line_handler.add(MessageEvent, message=TextMessage)
def on_text(event: MessageEvent):
    text = (event.message.text or "").strip()
    seq = parse_seq_from_text(text)
    if not seq:
        msg = (
            "æ ¼å¼å°æŠ„ï¼šè«‹è²¼ B P T åºåˆ—ï¼ˆæ”¯æ´ä¸­æ–‡ï¼šèŠ/é–’/å’Œï¼›å¯ç”¨é€—è™Ÿæˆ–ç©ºç™½åˆ†éš”ï¼‰\n"
            "ä¾‹ï¼šB P P B T Bã€æˆ–ï¼šèŠ é–’ é–’ èŠ å’Œ èŠ"
        )
        if line_bot_api:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(msg))
        return

    probs = predict_with_models(seq) if model_bundle.get("loaded") else predict_probs_from_seq_rule(seq)
    reply = render_reply(seq, probs, by_model=model_bundle.get("loaded", False))
    if line_bot_api:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(reply))

@line_handler.add(MessageEvent, message=ImageMessage)
def on_image(event: MessageEvent):
    # å¾ LINE æ‹‰å›å½±åƒ bytes
    seq: List[str] = []
    try:
        if not line_bot_api:
            raise RuntimeError("LINE config missing")
        content = line_bot_api.get_message_content(event.message.id)
        b = io.BytesIO()
        for chunk in content.iter_content():
            b.write(chunk)
        b.seek(0)
        img = Image.open(b).convert("RGB")
        seq = extract_sequence_from_image(img)  # TODO: æ¥ä¸Šä½ çš„å½±åƒç®¡ç·š
    except Exception as e:
        logger.exception(f"[image] fetch/parse error: {e}")

    if not seq:
        msg = (
            "åœ–ç‰‡æœªèƒ½è§£æå‡ºç‰Œè·¯ ğŸ˜µâ€ğŸ’«\n"
            "è«‹ç¢ºä¿ï¼šæˆªåœ–åŒ…å«å®Œæ•´å¤§è·¯/ä¸‹ä¸‰è·¯ã€ç•«è³ªæ¸…æ™°ã€é¿å…å£“ç¸®/åå…‰ã€‚\n"
            "ä¹Ÿå¯å…ˆæ”¹è²¼æ–‡å­—åºåˆ—ï¼ˆæ”¯æ´ï¼šB/P/T èˆ‡ èŠ/é–’/å’Œï¼‰ã€‚"
        )
        if line_bot_api:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(msg))
        return

    probs = predict_with_models(seq) if model_bundle.get("loaded") else predict_probs_from_seq_rule(seq)
    reply = render_reply(seq, probs, by_model=model_bundle.get("loaded", False))
    if line_bot_api:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(reply))


# -----------------------------------------
# Entrypoint
# -----------------------------------------
if __name__ == "__main__":
    port = int(os.getenv("PORT", "8000"))
    app.run(host="0.0.0.0", port=port, debug=True)
