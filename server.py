#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BGS Server (Dashboard + Dual-key predict + Feature-mode synth)
- Flask API
- Optional LINE webhook (enabled only if LINE env vars are set)
- Seed ingest + synthetic training + model-first predict
- 30-min trial timer per user (memory-based; single worker recommended)
- Graphical dashboard (/) and /health

Env:
  LINE_CHANNEL_SECRET, LINE_CHANNEL_ACCESS_TOKEN  # optional
  TRIAL_MINUTES=30
  ADMIN_UIDS=Uxxxxxxxx,Uyyyyyyyy  # optional for TRAIN/STATUS guard
  LOGIN_CODE=123456                # optional demo login code
  DATA_ROOT=/opt/data              # optional; default "."
  PORT=8000                        # local run
"""
from __future__ import annotations

import os
import json
import time
import random
import threading
from typing import List, Dict, Any

from pathlib import Path as _Path
from flask import Flask, request, jsonify, abort

app = Flask(__name__)
try:
    from flask_cors import CORS
    CORS(app)
except Exception:
    pass

# ---------- Trial settings ----------
TRIAL_MINUTES = int(os.getenv("TRIAL_MINUTES", "30"))
_trial_sessions: Dict[str, Dict[str, Any]] = {}  # userId -> {"start": epoch, "warned": False, "unlocked": False}

def trial_touch(user_id: str) -> Dict[str, Any]:
    s = _trial_sessions.get(user_id)
    if not s:
        s = {"start": time.time(), "warned": False, "unlocked": False}
        _trial_sessions[user_id] = s
    return s

def trial_check_and_maybe_warn(user_id: str, reply_fn):
    s = trial_touch(user_id)
    if s.get("unlocked"):
        return
    elapsed_min = (time.time() - s["start"]) / 60.0
    if elapsed_min >= TRIAL_MINUTES and not s.get("warned"):
        s["warned"] = True
        reply_fn(f"‚è∞ Ë©¶Áî®Â∑≤Ë∂ÖÈÅé {TRIAL_MINUTES} ÂàÜÈêòÔºåË´ãÂÆåÊàêÁôªÂÖ•ÊàñÁ∫åÊúü„ÄÇËã•Â∑≤ÂÆåÊàêÁôªÂÖ•‰ΩÜ‰ªçÁúãÂà∞Ê≠§Ë®äÊÅØÔºåËº∏ÂÖ•ÔºöRESET TRIAL")

# ---------- Storage paths ----------
ROOT = _Path(os.getenv("DATA_ROOT", "."))
DATA = ROOT / "data"; DATA.mkdir(exist_ok=True)
MODELS = ROOT / "models"; MODELS.mkdir(exist_ok=True)
REPORTS = ROOT / "reports"; REPORTS.mkdir(exist_ok=True)

SEED_CSV   = DATA / "seed.csv"
SIM_ROWS   = DATA / "sim_rows.csv"
MODEL_PATH = MODELS / "baseline.joblib"
PRIORS_JSON= REPORTS / "priors.json"

# ---------- Heuristic baseline ----------
OUTMAP = {"B":0, "P":1, "T":2}
INV_OUTMAP = {0:"B", 1:"P", 2:"T"}

def parse_text_seq(s: str) -> List[str]:
    toks = [t.strip().upper() for t in s.replace(",", " ").split() if t.strip().upper() in ("B","P","T")]
    return toks

def estimate_probs(seq: List[str]):
    k = min(12, len(seq)) or 1
    win = seq[-k:]
    cB = win.count("B") + 0.5
    cP = win.count("P") + 0.5
    cT = win.count("T") + 0.5
    s = cB + cP + cT
    probs = (cB/s, cP/s, cT/s)
    detail = {"window": k, "counts": {"B": cB, "P": cP, "T": cT}}
    return probs, detail

# ---------- Hot-train (synth + train) ----------
_hot_lock = threading.Lock()
_hot_training = False
_hot_last_metrics: Dict[str, Any] | None = None

try:
    import joblib
except Exception:
    joblib = None

def _append_seed_history(history: str) -> int:
    import pandas as pd
    toks = parse_text_seq(history)
    if len(toks) < 6:
        raise ValueError("history Èï∑Â∫¶Ëá≥Â∞ë 6")
    df_new = pd.DataFrame({"history":[" ".join(toks)]})
    if SEED_CSV.exists():
        df = pd.read_csv(SEED_CSV)
        df = pd.concat([df, df_new], ignore_index=True)
    else:
        df = df_new
    df.to_csv(SEED_CSV, index=False)
    return len(df)

def _read_seed_histories() -> List[List[str]]:
    import pandas as pd
    if not SEED_CSV.exists(): return []
    df = pd.read_csv(SEED_CSV)
    out = []
    for s in df["history"].astype(str).tolist():
        toks = parse_text_seq(s)
        if len(toks) >= 6:
            out.append(toks)
    return out

def _estimate_ngram(seqs: List[List[str]], order:int=2, laplace:float=0.5):
    """Estimate (order)-gram transition probabilities with Laplace smoothing."""
    from collections import defaultdict, Counter
    counts = defaultdict(Counter)
    for seq in seqs:
        if len(seq) <= order: continue
        for i in range(order, len(seq)):
            ctx = tuple(seq[i-order:i]); nxt = seq[i]
            counts[ctx][nxt] += 1
    vocab = ["B","P","T"]
    trans = {}
    for ctx, ctr in counts.items():
        total = sum(ctr.values()) + laplace*len(vocab)
        trans[ctx] = {v:(ctr[v]+laplace)/total for v in vocab}
    return trans

def _style_adjust(probs: Dict[str,float], last: str|None, style:str='hybrid', long_strength:float=0.5, jumpy_strength:float=0.5, tie_rate:float=0.06):
    pB, pP, pT = probs.get('B',1/3), probs.get('P',1/3), probs.get('T',1/3)
    pT = 0.85*pT + 0.15*tie_rate
    remain = max(1e-9, 1 - pT)
    s = max(pB+pP, 1e-12)
    pB, pP = remain*(pB/s), remain*(pP/s)
    if last in ("B","P"):
        if style in ("long","hybrid"):
            if last=="B": pB += 0.2*long_strength
            else: pP += 0.2*long_strength
        if style in ("jumpy","hybrid"):
            if last=="B": pP += 0.2*jumpy_strength
            else: pB += 0.2*jumpy_strength
    tot = pB+pP+pT
    if tot <= 0: return {"B":1/3,"P":1/3,"T":1/3}
    return {"B":pB/tot,"P":pP/tot,"T":pT/tot}

def _sample_next(probs: Dict[str,float]) -> str:
    r = random.random(); acc = 0.0
    for k in ("B","P","T"):
        acc += probs[k]
        if r <= acc: return k
    return "T"

def _gen_sequences(trans:dict, order:int, n_seq:int, min_len:int, max_len:int, style:str, long_strength:float, jumpy_strength:float, tie_rate:float):
    contexts = list(trans.keys())
    if not contexts: raise ValueError("ËΩâÁßªÁÇ∫Á©∫Ôºåseed ‰∏çË∂≥Êàñ order ÈÅéÂ§ß")
    seqs = []
    for _ in range(n_seq):
        cur = list(random.choice(contexts))
        L = random.randint(min_len, max_len)
        last = cur[-1] if cur else None
        while len(cur) < L:
            probs = trans.get(tuple(cur[-order:]), {"B":1/3,"P":1/3,"T":1/3})
            probs = _style_adjust(probs, last, style, 0.5, 0.5, tie_rate)
            nxt = _sample_next(probs)
            cur.append(nxt); last = nxt
        seqs.append(cur)
    return seqs

def _expand_rows(seqs: List[List[str]], max_history:int=12):
    import pandas as _pd
    rows = []
    for sid, seq in enumerate(seqs):
        streak = 0
        for i in range(len(seq)-1):
            cur = seq[:i+1]; nxt = seq[i+1]
            streak = 1 if i==0 else (streak+1 if cur[-1]==cur[-2] else 1)
            k = min(max_history, len(cur)); win = cur[-k:]
            wB=win.count('B')/k; wP=win.count('P')/k; wT=win.count('T')/k
            switches = sum(1 for j in range(1,len(win)) if win[j]!=win[j-1])
            osc = switches/(len(win)-1) if len(win)>1 else 0.0
            ctx1=cur[-1]; ctx2=''.join(cur[-2:]) if i>=1 else '_'+ctx1; ctx3=''.join(cur[-3:]) if i>=2 else '_'+ctx2
            rows.append({'seq_id':sid,'step':i,'streak':streak,'wB':wB,'wP':wP,'wT':wT,'osc':osc,'last':ctx1,'ctx1':ctx1,'ctx2':ctx2,'ctx3':ctx3,'y':OUTMAP[nxt]})
    df = _pd.DataFrame(rows)
    for col in ['last','ctx1','ctx2','ctx3']:
        d = _pd.get_dummies(df[col], prefix=col)
        df = _pd.concat([df.drop(columns=[col]), d], axis=1)
    return df

# --- Feature-mode helpers (ASCII-only docstrings to avoid Unicode parsing issues) ---
def _collect_seed_feature_rows(max_history:int=12):
    """Expand features directly from SEED histories (no n-gram synthesis). Return a DataFrame."""
    import pandas as pd
    seqs = _read_seed_histories()
    if not seqs:
        raise ValueError("No seed available. Please POST /ingest-seed first or use LINE: SEED: <B/P/T ...>")
    df_seed = _expand_rows(seqs, max_history=max_history)
    return df_seed

def _sample_feature_rows(df_seed, target_rows:int, jitter:float=0.02, random_seed:int=2025):
    """Resample-with-replacement from df_seed and add small Gaussian jitter to continuous features."""
    import numpy as np, pandas as pd
    rng = np.random.default_rng(random_seed)
    if len(df_seed) == 0:
        raise ValueError("df_seed is empty")
    idx = rng.integers(0, len(df_seed), size=target_rows)
    df = df_seed.iloc[idx].copy().reset_index(drop=True)
    # Jitter continuous features; clip to [0,1]; renormalize wB+wP+wT=1
    for col in ['wB','wP','wT','osc']:
        if col in df.columns:
            noise = rng.normal(0, jitter, size=len(df))
            df[col] = df[col].astype(float) + noise
    for col in ['wB','wP','wT','osc']:
        if col in df.columns:
            df[col] = df[col].clip(0.0, 1.0)
    if all(c in df.columns for c in ['wB','wP','wT']):
        s = (df['wB']+df['wP']+df['wT']).replace(0, 1.0)
        df['wB'] = df['wB']/s
        df['wP'] = df['wP']/s
        df['wT'] = df['wT']/s
    # Reassign pseudo seq/step for nicer distribution
    df['seq_id'] = (np.arange(len(df)) // 100).astype(int)
    df['step']   = (np.arange(len(df)) %  100).astype(int)
    # One-hot columns already present since df_seed came from _expand_rows
    return df

def _train_baseline(df, valid_ratio:float=0.1):
    from sklearn.model_selection import train_test_split
    X = df.drop(columns=['y']).values; y = df['y'].values
    Xtr, Xva, ytr, yva = train_test_split(X,y,test_size=valid_ratio,random_state=42,stratify=y)

    model_name = "LogisticRegression"
    try:
        import lightgbm as lgb  # optional
        clf = lgb.LGBMClassifier(n_estimators=400,learning_rate=0.05,num_leaves=63,subsample=0.9,colsample_bytree=0.9,random_state=42)
        model_name = "LightGBM"
    except Exception:
        try:
            import xgboost as xgb
            clf = xgb.XGBClassifier(n_estimators=500,max_depth=6,learning_rate=0.05,subsample=0.9,colsample_bytree=0.9,reg_lambda=1.0,objective='multi:softprob',num_class=3,random_state=42,tree_method='hist')
            model_name = "XGBoost"
        except Exception:
            from sklearn.linear_model import LogisticRegression
            clf = LogisticRegression(max_iter=200, multi_class='multinomial')
            model_name = "LogisticRegression"
    clf.fit(Xtr,ytr)
    from sklearn.metrics import log_loss
    pva = clf.predict_proba(Xva)
    acc = float((pva.argmax(1)==yva).mean())
    ll  = float(log_loss(yva,pva))
    if joblib is not None:
        try: joblib.dump(clf, MODEL_PATH)
        except Exception: pass
    return clf, {"valid_acc":acc,"logloss":ll,"model":model_name,"rows":int(len(df))}

def _synth_and_train(target_rows:int=300_000, order:int=2, style:str='hybrid', tie_rate:float=0.06, random_seed:int=2025, mode:str='ngram', jitter:float=0.02):
    import numpy as np, pandas as pd
    np.random.seed(random_seed); random.seed(random_seed)
    seqs = _read_seed_histories()
    if not seqs:
        raise ValueError("Ê≤íÊúâ seedÔºåË´ãÂÖà /ingest-seed ÊàñÂú® LINE ÊâìÔºöSEED: <B/P/T ‰∏≤>")
    if mode == 'feature':
        df_seed = _collect_seed_feature_rows(max_history=12)
        df = _sample_feature_rows(df_seed, target_rows=target_rows, jitter=jitter, random_seed=random_seed)
        df.to_csv(SIM_ROWS, index=False)
    elif mode == 'uniform':
        # Purely random baseline guided by global prior of seed tokens
        from collections import Counter
        rng = np.random.default_rng(random_seed)
        ctr = Counter()
        for s in seqs:
            for t in s:
                ctr[t]+=1
        total = sum(ctr.values()) or 1
        prior = {k: ctr.get(k,0)/total for k in ('B','P','T')}
        rows=[]
        for i in range(target_rows):
            wB,wP = rng.random(), rng.random()
            rem = max(1e-9, 1.0-wB)
            wP = rem * wP
            wT = max(0.0, 1.0 - (wB+wP))
            osc = rng.random()
            last = rng.choice(['B','P','T'])
            ctx2 = last + rng.choice(['B','P','T'])
            ctx3 = ctx2 + rng.choice(['B','P','T'])
            y = int(rng.choice([0,1,2], p=[prior['B'],prior['P'],prior['T']]))
            rows.append({'seq_id':i//100,'step':i%100,'streak':1,'wB':wB,'wP':wP,'wT':wT,'osc':osc,'last':last,'ctx1':last,'ctx2':ctx2,'ctx3':ctx3,'y':y})
        df = pd.DataFrame(rows)
        for col in ['last','ctx1','ctx2','ctx3']:
            d = pd.get_dummies(df[col], prefix=col); df = pd.concat([df.drop(columns=[col]), d], axis=1)
        df.to_csv(SIM_ROWS, index=False)
    else:
        trans = _estimate_ngram(seqs, order=order, laplace=0.5)
        sim: List[List[str]] = []; rows_est = 0
        while rows_est < target_rows:
            batch = _gen_sequences(trans, order, n_seq=200, min_len=60, max_len=120, style=style, long_strength=0.5, jumpy_strength=0.5, tie_rate=tie_rate)
            sim.extend(batch)
            rows_est = sum(max(0,len(s)-1) for s in sim)
        df = _expand_rows(sim, max_history=12)
        if len(df) > target_rows:
            df = df.sample(n=target_rows, random_state=random_seed).sort_index()
        df.to_csv(SIM_ROWS, index=False)

    _, metrics = _train_baseline(df, valid_ratio=0.1)
    with open(PRIORS_JSON,'w',encoding='utf-8') as f:
        json.dump({"order":order,"style":style,"tie_rate":tie_rate,"target_rows":target_rows,"mode":mode,"jitter":jitter, **metrics}, f, ensure_ascii=False, indent=2)
    return metrics

def _predict_next_with_model(history: str):
    if not (MODEL_PATH.exists() and joblib is not None):
        return None
    try:
        clf = joblib.load(MODEL_PATH)
    except Exception:
        return None
    import pandas as _pd
    toks = parse_text_seq(history)
    if len(toks) < 3: return None
    cur = toks; i = len(cur)-1
    k = min(12, len(cur)); win = cur[-k:]
    wB=win.count('B')/k; wP=win.count('P')/k; wT=win.count('T')/k
    switches = sum(1 for j in range(1,len(win)) if win[j]!=win[j-1])
    osc = switches/(len(win)-1) if len(win)>1 else 0.0
    ctx1=cur[-1]; ctx2=''.join(cur[-2:]) if i>=1 else '_'+ctx1; ctx3=''.join(cur[-3:]) if i>=2 else '_'+ctx2
    row={'seq_id':0,'step':i,'streak':1,'wB':wB,'wP':wP,'wT':wT,'osc':osc,'last':ctx1,'ctx1':ctx1,'ctx2':ctx2,'ctx3':ctx3}
    df=_pd.DataFrame([row])
    for col in ['last','ctx1','ctx2','ctx3']:
        d=_pd.get_dummies(df[col], prefix=col); df=_pd.concat([df.drop(columns=[col]), d], axis=1)
    if SIM_ROWS.exists():
        ref_cols=_pd.read_csv(SIM_ROWS, nrows=1).drop(columns=['y']).columns.tolist()
        for c in ref_cols:
            if c not in df.columns: df[c]=0
        df=df[ref_cols]
    proba = clf.predict_proba(df.values)[0]
    return {'B':float(proba[0]),'P':float(proba[1]),'T':float(proba[2])}

# ---------- REST ----------
@app.post("/ingest-seed")
def ingest_seed():
    data = request.get_json(silent=True) or {}
    history = str(data.get("history","")).strip()
    if not history:
        return jsonify({"ok":False,"msg":"history ÂøÖÂ°´"}), 400
    try:
        n = _append_seed_history(history)
        return jsonify({"ok":True,"seed_records": n}), 200
    except Exception as e:
        return jsonify({"ok":False,"error":str(e)}), 400

@app.post("/synth-train")
def synth_train():
    data = request.get_json(silent=True) or {}
    target_rows = int(data.get("target_rows", 300000))
    style = str(data.get("style","hybrid"))
    tie_rate = float(data.get("tie_rate", 0.06))
    mode = str(data.get("mode","ngram"))
    jitter = float(data.get("jitter", 0.02))
    with _hot_lock:
        if _hot_training:
            return jsonify({"ok":False,"msg":"training in progress"}), 409
    def _runner():
        global _hot_training, _hot_last_metrics
        try:
            with _hot_lock:
                _hot_training = True
            m = _synth_and_train(target_rows=target_rows, style=style, tie_rate=tie_rate, mode=mode, jitter=jitter)
            _hot_last_metrics = m
        except Exception as e:
            _hot_last_metrics = {"error": str(e)}
        finally:
            with _hot_lock:
                _hot_training = False
    t = threading.Thread(target=_runner, daemon=True)
    t.start()
    return jsonify({"ok":True,"msg":"started","mode":mode,"jitter":jitter,"target_rows":target_rows}), 200

@app.post("/predict")
def api_predict():
    data = request.get_json(silent=True) or {}
    seq_text = str(data.get("history",""))
    model_proba = _predict_next_with_model(seq_text)
    if model_proba is not None:
        probs = model_proba
        top_label = max(probs, key=probs.get)
        resp = {
            "ok": True,
            "source": "model",
            "probabilities": probs,  # legacy key
            "probs": probs,          # new key
            "top": top_label,
            "label": top_label
        }
        return jsonify(resp), 200
    seq = parse_text_seq(seq_text)
    p, detail = estimate_probs(seq)
    probs = {"B":p[0],"P":p[1],"T":p[2]}
    top_label = max(probs, key=probs.get)
    resp = {
        "ok": True,
        "source": "heuristic",
        "probabilities": probs,
        "probs": probs,
        "top": top_label,
        "label": top_label,
        "detail": detail
    }
    return jsonify(resp), 200

# ---------- Dashboard & Health ----------
@app.get("/health")
def health():
    return "OK", 200

@app.get("/")
def home():
    seed_n = 0
    if SEED_CSV.exists():
        try:
            import pandas as _pd
            seed_n = len(_pd.read_csv(SEED_CSV))
        except Exception:
            seed_n = 0
    status = {
        "seed_records": seed_n,
        "model_exists": MODEL_PATH.exists(),
        "is_training": _hot_training,
        "last_metrics": _hot_last_metrics,
        "webhook": "/line-webhook",
        "health": "/health",
    }
    accept = request.headers.get("Accept","")
    if "application/json" in accept:
        return jsonify(status)
    # Graphical dashboard (pure HTML+JS)
    return f"""<!doctype html>
<html lang="zh-Hant"><head>
<meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>BGS Dashboard</title>
<style>
  body{{font-family:ui-sans-serif,system-ui;background:#0d1117;color:#c9d1d9;padding:24px}}
  .card{{background:#111827;border:1px solid #1f2937;border-radius:12px;padding:16px;margin:12px 0}}
  .row{{display:flex;gap:8px;align-items:center;flex-wrap:wrap}}
  .grid{{display:grid;gap:12px}}
  .grid-2{{grid-template-columns:1fr 1fr}}
  input,textarea,select,button{{background:#0b1220;color:#e5e7eb;border:1px solid #374151;border-radius:8px;padding:8px}}
  button{{cursor:pointer}}
  pre{{white-space:pre-wrap;word-break:break-word;background:#0b1220;padding:12px;border-radius:8px}}
  .muted{{color:#94a3b8}}
</style></head>
<body>
  <h2>BGS Dashboard</h2>
  <div class="card">
    <div class="row">
      <button onclick="refreshStatus()">ÈáçÊñ∞Êï¥ÁêÜÁãÄÊÖã</button>
      <span class="muted">WebhookÔºö<code>/line-webhook</code></span>
      <span class="muted">ÂÅ•Â∫∑Ê™¢Êü•Ôºö<code>/health</code></span>
    </div>
    <pre id="statusBox">ËºâÂÖ•‰∏≠‚Ä¶</pre>
  </div>

  <div class="grid grid-2">
    <div class="card">
      <h3>Âç≥ÊôÇÈ†êÊ∏¨ /predict</h3>
      <div class="row">
        <input id="predInput" placeholder="‰æãÂ¶ÇÔºöB P P T B" style="flex:1"/>
        <button onclick="doPredict()">ÈÄÅÂá∫</button>
      </div>
      <pre id="predBox"></pre>
    </div>
    <div class="card">
      <h3>ËøΩÂä†Á®ÆÂ≠ê /ingest-seed</h3>
      <textarea id="seedInput" rows="4" placeholder="Ë≤º‰∏äÁúüÂØ¶Ê≠∑Âè≤ÔºöB P B P T B ‚Ä¶"></textarea>
      <div class="row"><button onclick="doSeed()">ËøΩÂä†</button></div>
      <pre id="seedBox"></pre>
    </div>
  </div>

  <div class="card">
    <h3>ÂïüÂãïË®ìÁ∑¥ /synth-train</h3>
    <div class="row">
      <label>rows</label><input id="rows" type="number" value="300000" style="width:160px"/>
      <label>style</label><select id="style"><option>hybrid</option><option>jumpy</option><option>long</option></select>
      <label>tie_rate</label><input id="tie" type="number" step="0.01" value="0.06" style="width:120px"/>
      <label>mode</label><select id="mode"><option value="ngram" selected>ngram</option><option value="feature">feature</option><option value="uniform">uniform</option></select>
      <label>jitter</label><input id="jitter" type="number" step="0.005" value="0.02" style="width:120px"/>
      <button onclick="doTrain()">ÈñãÂßãË®ìÁ∑¥</button>
    </div>
    <pre class="muted">ÊèêÁ§∫ÔºöÂÖà‰ª• 120000ÔΩû200000 Ê∏¨Ë©¶ÔºõËã•Ë¶Å„ÄåÁâπÂæµÈö®Ê©üÁîüÊàê„ÄçÔºåmode Ë´ãÈÅ∏ feature„ÄÇ</pre>
    <pre id="trainBox"></pre>
  </div>

<script>
async function refreshStatus(){try{const r=await fetch(location.origin + "/",{headers:{"Accept":"application/json"}});const j=await r.json();document.getElementById("statusBox").textContent=JSON.stringify(j,null,2);}catch(e){document.getElementById("statusBox").textContent="ËÆÄÂèñÂ§±ÊïóÔºö"+e;}}
async function doPredict(){const history=document.getElementById("predInput").value.trim();const r=await fetch("/predict",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({history})});const j=await r.json();document.getElementById("predBox").textContent=JSON.stringify(j,null,2);}
async function doSeed(){const history=document.getElementById("seedInput").value.trim();const r=await fetch("/ingest-seed",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({history})});const j=await r.json();document.getElementById("seedBox").textContent=JSON.stringify(j,null,2);refreshStatus();}
async function doTrain(){const target_rows=parseInt(document.getElementById("rows").value||"300000",10);const style=document.getElementById("style").value;const tie_rate=parseFloat(document.getElementById("tie").value||"0.06");const mode=document.getElementById('mode').value;const jitter=parseFloat(document.getElementById('jitter').value||'0.02');const r=await fetch("/synth-train",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({target_rows,style,tie_rate,mode,jitter})});const j=await r.json();document.getElementById("trainBox").textContent=JSON.stringify(j,null,2);refreshStatus();}
refreshStatus();
</script>
</body></html>"""

# ---------- Optional LINE webhook ----------
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
ADMIN_UIDS = [x.strip() for x in os.getenv("ADMIN_UIDS","").split(",") if x.strip()]

_line_enabled = bool(LINE_CHANNEL_SECRET and LINE_CHANNEL_ACCESS_TOKEN)
if _line_enabled:
    from linebot import LineBotApi, WebhookParser
    from linebot.models import MessageEvent, TextMessage, TextSendMessage
    from linebot.exceptions import InvalidSignatureError

    line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
    parser = WebhookParser(LINE_CHANNEL_SECRET)

    def reply_or_push(event, message: TextSendMessage | str):
        if isinstance(message, str):
            message = TextSendMessage(text=message)
        try:
            if getattr(event, "reply_token", None):
                line_bot_api.reply_message(event.reply_token, message)
            else:
                uid = getattr(event.source, "user_id", None)
                if uid:
                    line_bot_api.push_message(uid, message)
        except Exception as e:
            print("LINE send error:", e, flush=True)

    @app.post("/line-webhook")
    def line_webhook():
        sig = request.headers.get("X-Line-Signature", "")
        body = request.get_data(as_text=True)
        try:
            events = parser.parse(body, sig)
        except InvalidSignatureError:
            abort(400)
        for event in events:
            if isinstance(event, MessageEvent) and isinstance(event.message, TextMessage):
                on_text(event)
        return "OK"

    def on_text(event):
        text = (event.message.text or "").strip()
        user_id = getattr(event.source, "user_id", "unknown")

        def _reply(msg: str):
            reply_or_push(event, TextSendMessage(text=msg))

        # Trial check (per message)
        trial_check_and_maybe_warn(user_id, _reply)

        up = text.upper()

        # Maintenance commands
        if up == "RESET TRIAL":
            _trial_sessions.pop(user_id, None)
            _reply("‚úÖ Â∑≤ÈáçÁΩÆ‰Ω†ÁöÑË©¶Áî®ÂÄíÊï∏ËàáËß£ÈéñÁãÄÊÖã„ÄÇ")
            return
        if up.startswith("LOGIN "):
            code = text.split(" ",1)[1].strip()
            ok_code = os.getenv("LOGIN_CODE", "123456")
            if code == ok_code:
                s = trial_touch(user_id); s["unlocked"] = True
                _reply("‚úÖ ÁôªÂÖ•ÊàêÂäüÔºåÂ∑≤Ëß£Èô§Ë©¶Áî®ÈôêÂà∂„ÄÇ")
            else:
                _reply("‚ùå ÁôªÂÖ•Á¢ºÈåØË™§")
            return

        def is_admin(uid: str) -> bool:
            return (uid in ADMIN_UIDS) or (not ADMIN_UIDS)  # Ê≤íË®≠ÂÆö ADMIN_UIDS Ââá‰∏çÈôêÂà∂

        # Hot-train commands
        if up.startswith("SEED:"):
            history = text.split(":",1)[1]
            try:
                n = _append_seed_history(history)
                _reply(f"‚úÖ Â∑≤ËøΩÂä† seedÔºàÂÖ± {n} Á≠ÜÔºâ„ÄÇÂèØ‰∏ãÔºöTRAIN 300000 hybrid 0.06 feature 0.02")
            except Exception as e:
                _reply(f"‚ùå ËøΩÂä†Â§±ÊïóÔºö{e}")
            return

        if up.startswith("TRAIN"):  # TRAIN rows [style] [tie] [mode] [jitter]
            if not is_admin(user_id):
                _reply("‚õî ÂÉÖÁÆ°ÁêÜÂì°ÂèØÂïüÂãïË®ìÁ∑¥")
                return
            parts = text.split()
            target = int(parts[1]) if len(parts)>=2 else 300000
            style  = parts[2] if len(parts)>=3 else "hybrid"
            try:
                tie = float(parts[3]) if len(parts)>=4 else 0.06
            except Exception:
                tie = 0.06
            mode = parts[4] if len(parts)>=5 else 'ngram'
            try:
                jitter = float(parts[5]) if len(parts)>=6 else 0.02
            except Exception:
                jitter = 0.02
            def _runner():
                _synth_and_train(target_rows=target, style=style, tie_rate=tie, mode=mode, jitter=jitter)
            threading.Thread(target=_runner, daemon=True).start()
            _reply(f"üöÄ ÈñãÂßãË®ìÁ∑¥Ôºörows={target} style={style} tie={tie} mode={mode} jitter={jitter}")
            return

        if up.startswith("STATUS"):
            if not is_admin(user_id):
                _reply("‚õî ÂÉÖÁÆ°ÁêÜÂì°ÂèØÊü•Ë©¢Ë®ìÁ∑¥ÁãÄÊÖã")
                return
            if _hot_training:
                _reply("üîÑ Ë®ìÁ∑¥‰∏≠‚Ä¶")
            else:
                if _hot_last_metrics and "error" not in _hot_last_metrics:
                    _reply(f"‚úÖ ÊúÄËøëÊ®°ÂûãÔºö{_hot_last_metrics.get('model')} acc={_hot_last_metrics.get('valid_acc'):.3f} logloss={_hot_last_metrics.get('logloss'):.3f}")
                elif _hot_last_metrics and "error" in _hot_last_metrics:
                    _reply(f"‚ùå ‰∏äÊ¨°Ë®ìÁ∑¥ÈåØË™§Ôºö{_hot_last_metrics['error']}")
                else:
                    _reply("‚ÑπÔ∏è Â∞öÁÑ°Ë®ìÁ∑¥Á¥ÄÈåÑ")
            return

        if up.startswith("PRED "):
            hist = text.split(" ",1)[1]
            model_proba = _predict_next_with_model(hist)
            if model_proba is not None:
                _reply(f"Ê®°ÂûãÊ©üÁéá ‚Üí Ëéä {model_proba['B']:.2f}ÔΩúÈñí {model_proba['P']:.2f}ÔΩúÂíå {model_proba['T']:.2f}")
            else:
                seq_tmp = parse_text_seq(hist)
                p, _ = estimate_probs(seq_tmp)
                _reply(f"ÂïüÁôºÂºèÊ©üÁéá ‚Üí Ëéä {p[0]:.2f}ÔΩúÈñí {p[1]:.2f}ÔΩúÂíå {p[2]:.2f}")
            return

        _reply("Êåá‰ª§ÔºöSEED: <Ë∑ØÂñÆ> ÔΩú TRAIN <rows> [style] [tie] [mode] [jitter] ÔΩú STATUS ÔΩú PRED <Ë∑ØÂñÆ> ÔΩú LOGIN <code> ÔΩú RESET TRIAL")

else:
    def on_text(event):
        pass

if __name__ == "__main__":
    port = int(os.getenv("PORT", "8000"))
    app.run(host="0.0.0.0", port=port, debug=False)
